# robots.txt for BookEase - Optimized for Maximum SEO Performance
# Generated with AI assistance on 2026-01-14
# Last updated: 2026-01-14

# Global crawler directives - Allow beneficial crawlers, restrict harmful ones
User-agent: *
Allow: /
Disallow: /admin/
Disallow: /api/private/
Disallow: /checkout/
Disallow: /confirmation/
Disallow: /success/
Disallow: /*.json$
Disallow: /*?*
Disallow: /debug/

# Allow important content that drives SEO value
Allow: /service/
Allow: /mumbai
Allow: /delhi
Allow: /bangalore
Allow: /pune
Allow: /hyderabad
Allow: /chennai
Allow: /kolkata
Allow: /ahmedabad
Allow: /goa
Allow: /jaipur
Allow: /blog/
Allow: /help-center/
Allow: /contact-us/
Allow: /sitemap
Allow: /sitemap-*.xml$

# Google-specific optimization
User-agent: Googlebot
Allow: /
Disallow: /admin/
Disallow: /api/private/
Disallow: /checkout/
Disallow: /confirmation/
Disallow: /success/
Crawl-delay: 0

# Bing optimization
User-agent: Bingbot
Allow: /
Disallow: /admin/
Disallow: /api/private/
Disallow: /checkout/
Disallow: /confirmation/
Disallow: /success/
Crawl-delay: 0

# Image crawler optimization
User-agent: Googlebot-Image
User-agent: Bingbot-Image
Allow: /
Disallow: /admin/
Disallow: /api/private/

# Video crawler optimization
User-agent: Googlebot-Video
Allow: /
Disallow: /admin/
Disallow: /api/private/

# Social media crawlers
User-agent: facebookexternalhit
User-agent: Twitterbot
User-agent: LinkedInBot
Allow: /
Disallow: /admin/
Disallow: /api/private/
Disallow: /checkout/
Disallow: /confirmation/

# Block harmful crawlers that consume bandwidth without value
User-agent: AhrefsBot
Disallow: /

User-agent: SemrushBot
Disallow: /

User-agent: MJ12bot
Disallow: /

User-agent: DotBot
Disallow: /

User-agent: YandexBot
Disallow: /

User-agent: Baiduspider
Disallow: /

# Sitemap declarations - Point to our optimized sitemap index
Sitemap: https://bookease.com/sitemap-index.xml

# Additional sitemaps for specialized content
Sitemap: https://bookease.com/sitemap-pages.xml
Sitemap: https://bookease.com/sitemap-cities.xml
Sitemap: https://bookease.com/sitemap-services.xml
Sitemap: https://bookease.com/sitemap-special.xml
Sitemap: https://bookease.com/sitemap-images.xml

# Host directive for international targeting
Host: bookease.com

# Clean parameter handling for better crawling
Clean-param: utm_source&utm_medium&utm_campaign&utm_term&utm_content
Clean-param: gclid
Clean-param: fbclid

# Crawl rate optimization - Allow aggressive crawling for fresh content
Crawl-delay: 0

# Mobile-specific directives
User-agent: Googlebot-Mobile
Allow: /
Disallow: /admin/
Disallow: /api/private/

# News crawlers (if applicable)
User-agent: Googlebot-News
Allow: /blog/
Disallow: /admin/
Disallow: /api/private/

# Documentation for maintainers:
# - Update sitemap references when adding new content types
# - Review disallow rules quarterly to ensure important pages aren't blocked
# - Monitor crawl stats in Google Search Console regularly
# - Test robots.txt changes with Google's robots.txt tester tool